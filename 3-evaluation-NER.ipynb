{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Lily Grumbach\n",
    "    <br>M1 Humanités numériques - Université PSL</h4>\n",
    "<h1><center>Rendu TAIS-TAL </center></h1>\n",
    "<h2><center>Partie TAL</center></h2>\n",
    "<h3><center>2/3 : Reconnaissance d'entités nommées sur Doccano  -   Evaluation</center></h3>\n",
    "\n",
    "<b><u>PLAN:</u></b>\n",
    "1) Exploration des données\n",
    "<br>\n",
    "**2) NER avec Doccano**\n",
    "\n",
    "    a) initialisation des données\n",
    "    b) Exploration de la NER préalable de Spacy\n",
    "    c) Mise en place de la stratégie pour l'annotation sur Doccano\n",
    "    d) Entraînement par 5-fold cross validation\n",
    "    e) Evaluation des annotations\n",
    "\n",
    "3) Application du NER au df\n",
    "\n",
    "**Enjeux de la partie 2:**\n",
    "Les deux revues scientifiques étudiées reposent sur trois éléments consitutifs: \n",
    "- **Thématiques** : \n",
    "    - Hygiène \n",
    "    - Pathologies dites \"exotiques\" ou \"coloniales\"\n",
    "    - Liens avec les sciences humaines et sociales \n",
    "    - Relations avec les découvertes récentes\n",
    "- **Terrains spécifiques**  : \n",
    "    - Colonies et protectorats français\n",
    "    - Batiments navals de la marine française\n",
    "    - Autres territoires hors métropole et possessions françaises\n",
    "    - Dans certains cas des laboratoires\n",
    "- **Corps de métier** Population particulière de rédacteurs que sont les membres du corps de santé des colonies et du corps de médecine navale(fait l'objet d'une analyse de réseau non prise en considération dans ce devoir)\n",
    "\n",
    "\n",
    "**Objectifs de la partie 2:**\n",
    "- Entraîner une NER sur notre BDD\n",
    "\n",
    "<br></br>\n",
    "**L'objectif à long terme** de cet entraînement NER est de :\n",
    "- Mettre en place une NER qui pourrait être appliquée au full text de chacune des revues une fois les OCR nettoyées. \n",
    "- Appliquer cette NER à la revue des Archives de médecine navale et coloniale (1892-1898)\n",
    "- Alimenter une future base de données relationnelle\n",
    "\n",
    "\n",
    "**Limites de mon travail:** Il me sera nécessaire de mesurer si elle fonctionne bien à la fois sur le reste de la période étudiée ainsi que sur le Bulletin de la Société de Pathologie exotique\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fr_core_news_md'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d08c6ad20b2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Généraux :\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfr_core_news_md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fr_core_news_md'"
     ]
    }
   ],
   "source": [
    "#Généraux : \n",
    "import spacy\n",
    "import fr_core_news_md\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "#Importation de mon module d'éval\n",
    "import evaluation_NER\n",
    "from evaluation_NER import Matrics\n",
    "\n",
    "#Importation de mon module d'entrainement\n",
    "import Training_Doccano\n",
    "from Training_Doccano import pandas_to_doccano\n",
    "from Training_Doccano import train_data\n",
    "from Training_Doccano import train_nlp\n",
    "\n",
    "#Autres\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORG: {'TP': 1, 'TN': 0, 'FP': 0, 'FN': 1}\n",
      "PER: {'TP': 0, 'TN': 0, 'FP': 1, 'FN': 1}\n",
      "ORG: f1 0.6667, precision 1.0000, recall 0.5000\n",
      "PER: f1 0.0000, precision 0.0000, recall 0.0000\n"
     ]
    }
   ],
   "source": [
    "## Exemple donné dans le tutoriel :\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    sents_true_labels = [[{'start_idx': 0, 'end_idx': 1, 'text': 'Foreign Ministry', 'label': 'ORG'}, \n",
    "                          {'start_idx': 3, 'end_idx': 4, 'text': 'Shen Guofang', 'label': 'PER'},\n",
    "                          {'start_idx': 6, 'end_idx': 6, 'text': 'Reuters', 'label': 'ORG'}]]\n",
    "                        \n",
    "    sents_pred_labels = [[{'start_idx': 3, 'end_idx': 3, 'text': 'Shen', 'label': 'PER'},\n",
    "                          {'start_idx': 6, 'end_idx': 6, 'text': 'Reuters', 'label': 'ORG'}]]\n",
    "\n",
    "matrics = Matrics(sents_true_labels, sents_pred_labels)\n",
    "matrics.cal_confusion_matrices()\n",
    "matrics.print_confusion_matrices()\n",
    "matrics.cal_scores()\n",
    "matrics.print_scores() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tout notre enjeu est d'obtenir de notre texte les listes de listes de dictionnaires et faire correspondre les gold entities avec les prédictions. La tache n'est pas simple puisque nous devons itérer pour chacun de nos titres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application du nouveau modèle nlp sur le test_set1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####PREDICTION TEST_SET1\n",
    "\n",
    "#importation du fichier txt de test_set1 :\n",
    "with open (\"./Notebook_data/Training_Doccano/train-test_sets_articles/test_set1\") as f:\n",
    "    test_set1_list = f.readlines()\n",
    "# test_set1 = \"\".join(test_set1_list)\n",
    "# print(test_set1_list)\n",
    "\n",
    "#Application du nouveau nlp au test set\n",
    "nlp_path = \"./Notebook_data/Training_Doccano/trained_nlp/nlp1\"\n",
    "nlp_test1 = spacy.load(nlp_path)\n",
    "\n",
    "#Modèle prédictif sur le test_set1\n",
    "Liste_pred = []\n",
    "for article in test_set1_list:\n",
    "    article = re.sub(r'(^ {1,2})',\"\",article)\n",
    "    pred = nlp_test1(article)\n",
    "    ents = list(pred)\n",
    "    Liste_pred.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(géographie médicale, fièvre bilieuse hémoglobinurique)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vérification que le nlp est bien passé:\n",
    "Liste_pred[5].ents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Commentaire : </b>\n",
    "Le NLPsemble être assez correct dansl'ensemble!On remarque toutefois des incohérences : \n",
    "- \"tsé\" comme SHS\n",
    "- \"Terre\", \"malgaches\" comme GPE\n",
    "- \"Dr Barbe\" comme ORG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3. Evaluation du nouveau NLP\n",
    "\n",
    "Je dois pour cela annoter moi-même le test_set1 come \"gold standard\" et en comparer les résultats avec ceux de la prédiction juste au dessus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Après annotation manuelle, j'importe ke test_set1-annotated \n",
    "path_testset1annotated=\"./DOCCANO/doccano-output/test_set1-annotated.jsonl\"\n",
    "\n",
    "#Conversion au format TRAIN_DATA pour la manipulation\n",
    "gold_testset1=train_data(path_testset1annotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold_testset1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création d'un dataframe de nos articles que l'on va remplir avec les annotations pour y vois plus clair :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_gold = pd.DataFrame(gold_testset1)\n",
    "df_gold = df_gold.rename(columns={\"entities\":\"gold_annotations\",\"text\":\"article_titre\"})\n",
    "# df_gold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etrange mais pour avoir les données dansl'exacte même disposition, on va en fait ce qu'on va faire pour avoir les exactes mêmes types de données en gold et en prediction c'est qu'on va traiter les prédictions comme si on allait les exporter puis importer de Doccano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(df_gold[\"article_titre\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File created!\n"
     ]
    }
   ],
   "source": [
    "pandas_to_doccano(df,nlp_test1,\"./Notebook_data/Apply_Doccano-df/prediction_testset1.csv\")            \n",
    "\n",
    "pred_data = train_data(\"./Notebook_data/Apply_Doccano-df/prediction_testset1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred=pd.DataFrame(pred_data)\n",
    "df_pred=df_pred.rename(columns={\"entities\":\"gold_annotations\",\"text\":\"article_titre\"})\n",
    "\n",
    "df_pred_gold = pd.merge(df_gold,df_pred,how=\"left\",on=\"article_titre\")\n",
    "df_pred_gold= df_pred_gold.rename(columns={\"gold_annotations_x\":\"gold_annotations\",\"gold_annotations_y\" : \"pred_annotations\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pred_gold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Commentaire manuel : </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_titre</th>\n",
       "      <th>gold_annotations</th>\n",
       "      <th>pred_annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Variétés. / Concours sur l'organisation des se...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Géographie médicale. Notes sur le Yun-Nan (Chi...</td>\n",
       "      <td>[(34, 41, GPE), (43, 48, GPE), (0, 19, SHS)]</td>\n",
       "      <td>[(0, 19, SHS), (34, 41, GPE), (43, 48, GPE)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Variétés. Préjugés des Hindous sur la variole.</td>\n",
       "      <td>[(23, 30, SHS), (38, 45, PATH)]</td>\n",
       "      <td>[(23, 30, SHS), (38, 45, PATH)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>De l'emploi du paddy (riz non décortiqué) dans...</td>\n",
       "      <td>[(50, 58, PATH)]</td>\n",
       "      <td>[(15, 20, CHEM-LABO), (50, 58, PATH)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Analyse des eaux servant actuellement à l'alim...</td>\n",
       "      <td>[(70, 77, GPE)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>Vingt hystérectomies abdominales. Résultats te...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Épidémie d'ophtalmie purulente observée dans l...</td>\n",
       "      <td>[(11, 30, PATH), (49, 82, GPE), (139, 149, ZOO...</td>\n",
       "      <td>[(11, 30, PATH)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Statistique générale de la morbidité et de la ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>Le choléra à bord de la « Comète », par le Dr ...</td>\n",
       "      <td>[(3, 10, PATH)]</td>\n",
       "      <td>[(3, 10, PATH)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Maladie du sommeil. Trypanosomiases animales e...</td>\n",
       "      <td>[(64, 80, GPE), (48, 55, ZOO-ENTO), (20, 44, Z...</td>\n",
       "      <td>[(0, 18, PATH), (64, 80, GPE)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Instructions pour l'emploi du sérum antivénimeux</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>Hygiène navale à bord de l'amiral-Tréhouart, p...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Variétés. Statistique de la marine Japonaise p...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>Variétés. Activité maritime de la croix-rouge</td>\n",
       "      <td>[(34, 45, ORG)]</td>\n",
       "      <td>[(34, 45, ORG)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Éléphantasis du scrotum pesant 80 kilos. Extra...</td>\n",
       "      <td>[(0, 23, PATH)]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         article_titre  \\\n",
       "192  Variétés. / Concours sur l'organisation des se...   \n",
       "19   Géographie médicale. Notes sur le Yun-Nan (Chi...   \n",
       "22      Variétés. Préjugés des Hindous sur la variole.   \n",
       "54   De l'emploi du paddy (riz non décortiqué) dans...   \n",
       "86   Analyse des eaux servant actuellement à l'alim...   \n",
       "288  Vingt hystérectomies abdominales. Résultats te...   \n",
       "3    Épidémie d'ophtalmie purulente observée dans l...   \n",
       "93   Statistique générale de la morbidité et de la ...   \n",
       "220  Le choléra à bord de la « Comète », par le Dr ...   \n",
       "113  Maladie du sommeil. Trypanosomiases animales e...   \n",
       "13    Instructions pour l'emploi du sérum antivénimeux   \n",
       "280  Hygiène navale à bord de l'amiral-Tréhouart, p...   \n",
       "194  Variétés. Statistique de la marine Japonaise p...   \n",
       "282      Variétés. Activité maritime de la croix-rouge   \n",
       "18   Éléphantasis du scrotum pesant 80 kilos. Extra...   \n",
       "\n",
       "                                      gold_annotations  \\\n",
       "192                                                 []   \n",
       "19        [(34, 41, GPE), (43, 48, GPE), (0, 19, SHS)]   \n",
       "22                     [(23, 30, SHS), (38, 45, PATH)]   \n",
       "54                                    [(50, 58, PATH)]   \n",
       "86                                     [(70, 77, GPE)]   \n",
       "288                                                 []   \n",
       "3    [(11, 30, PATH), (49, 82, GPE), (139, 149, ZOO...   \n",
       "93                                                  []   \n",
       "220                                    [(3, 10, PATH)]   \n",
       "113  [(64, 80, GPE), (48, 55, ZOO-ENTO), (20, 44, Z...   \n",
       "13                                                  []   \n",
       "280                                                 []   \n",
       "194                                                 []   \n",
       "282                                    [(34, 45, ORG)]   \n",
       "18                                     [(0, 23, PATH)]   \n",
       "\n",
       "                                 pred_annotations  \n",
       "192                                            []  \n",
       "19   [(0, 19, SHS), (34, 41, GPE), (43, 48, GPE)]  \n",
       "22                [(23, 30, SHS), (38, 45, PATH)]  \n",
       "54          [(15, 20, CHEM-LABO), (50, 58, PATH)]  \n",
       "86                                             []  \n",
       "288                                            []  \n",
       "3                                [(11, 30, PATH)]  \n",
       "93                                             []  \n",
       "220                               [(3, 10, PATH)]  \n",
       "113                [(0, 18, PATH), (64, 80, GPE)]  \n",
       "13                                             []  \n",
       "280                                            []  \n",
       "194                                            []  \n",
       "282                               [(34, 45, ORG)]  \n",
       "18                                             []  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sample1 = pd.read_pickle('./Notebook_data/Apply_Doccano-df/Sample1_df_pred_gold.pkl')\n",
    "Sample2 = pd.read_pickle('./Notebook_data/Apply_Doccano-df/Sample2_df_pred_gold.pkl')\n",
    "Sample2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(64, 80, 'GPE'), (48, 55, 'ZOO-ENTO'), (20, 44, 'ZOO-ENTO'), (0, 18, 'PATH')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sample2.iloc[9,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul manuel \n",
    "#### Sample 1\n",
    "\n",
    "::: center\n",
    "  ------- ------- ------- -------\n",
    "                           Total\n",
    "           TP=9    FP=2    r1=11\n",
    "           FN=4    TN=80   r2=19\n",
    "   Total   13=c1   17=c2   30=t\n",
    "  ------- ------- ------- -------\n",
    ":::\n",
    "\n",
    "$$AccuracySample1 =  \\frac{TP + TN}{TP + TN + FP + FN} = \\frac{9+80}{9+80+4+2} = 0.93$$\n",
    "$$PrecisionSample1 =  \\frac{TP}{TP + FP} = \\frac{9}{9+4} = 0.69$$\n",
    "\n",
    "\n",
    "\n",
    "#### Sample 2\n",
    "::: center\n",
    "  ------- ------- ------- -------\n",
    "                           Total\n",
    "           TP=10   FP=1    r1=11\n",
    "           FN=5    TN=80   r2=85\n",
    "   Total   15=c1   81=c2   96=t\n",
    "  ------- ------- ------- -------\n",
    ":::\n",
    "\n",
    "$$AccuracySample2 =  \\frac{TP + TN}{TP + TN + FP + FN} = \\frac{10+80}{10+80+1+5} = 0.94$$\n",
    "$$PrecisionSample1 =  \\frac{TP}{TP + FP} = \\frac{10}{10+5} = 0.66$$\n",
    "\n",
    "\n",
    "### On observe que notre NLP a une assez bonne accuracy mais que la précision est par contre mauvaise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pour rappel, on cherche à avoir un modèle du type : \n",
    "\n",
    "`sents_true_labels = [[{'start_idx': pos0, 'end_idx': pos1, 'text': 'Token', 'type': 'token_label'}, .....]]`\n",
    "   \n",
    "   \n",
    "   ==> Donc dans mon cas je dois avoir pour CHAQUE ARTICLE,une liste contenant les dictionnaires associés \n",
    "   \n",
    "`sents_pred_labels = [[{'start_idx': pos0, 'end_idx': pos1, 'text': 'Token', 'type': 'token_label'}, .....]]`\n",
    "\n",
    "\n",
    "Donc il faut que pour chaque annotation, je passe la liste de tuples en liste de dictionnaires ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_set = ['SHS', 'GPE', 'PATH', 'ZOO-ENTO', 'LOC', 'CHEM-LABO', 'ORG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_gold = df_pred_gold.assign(gold_sents=lambda df_pred_gold: None)\n",
    "df_pred_gold = df_pred_gold.assign(pred_sents=lambda df_pred_gold: None)\n",
    "\n",
    "\n",
    "for i in range (len(df_pred_gold)):\n",
    "    sents_true_labels=[]\n",
    "    dico_tok={'start_idx': None, 'end_idx': None, 'text':None, 'label': None}\n",
    "    gold_annotation=df_pred_gold.iloc[i,1] \n",
    "    pred_annotation =df_pred_gold.iloc[i,2]\n",
    "    text=df_pred_gold.iloc[i,0]\n",
    "    \n",
    "    for token in gold_annotation:\n",
    "        if token[2] in entity_set:\n",
    "            dico_tok['start_idx']=token[0]\n",
    "            dico_tok['end_idx']=token[1]\n",
    "            dico_tok['label']=token[2]\n",
    "            dico_tok['text']=text[token[0]:token[1]]\n",
    "    sents_true_labels.append(dico_tok)\n",
    "    df_pred_gold.iloc[i,3]=sents_true_labels\n",
    "    \n",
    "    dico_tok2={'start_idx': None, 'end_idx': None, 'text':None, 'label': None}\n",
    "    for token in pred_annotation:\n",
    "        if token[2] in entity_set:\n",
    "            dico_tok2['start_idx']=token[0]\n",
    "            dico_tok2['end_idx']=token[1]\n",
    "            dico_tok2['label']=token[2]\n",
    "            dico_tok2['text']=text[token[0]:token[1]]\n",
    "    sents_pred_labels.append(dico_tok2)\n",
    "    df_pred_gold.iloc[i,4]=sents_pred_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je ne comprends pas pourquoi cela ne fonctionne pas dans le cas de pred_annotations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_true_labels=df_pred_gold[\"gold_sents\"].tolist()\n",
    "sents_pred_labels=df_pred_gold[\"pred_sents\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrics = Matrics(sents_true_labels, sents_pred_labels)\n",
    "matrics.cal_confusion_matrices()\n",
    "matrics.print_confusion_matrices()\n",
    "matrics.cal_scores()\n",
    "print(\"\\n\")\n",
    "matrics.print_scores() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour avoir une idée du nombre de d'annotations prédites/dans le gold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('pred : ',len(Liste_pred),'\\ngold : ',len(gold_testset1))\n",
    "\n",
    "##Effacer la dernière entrée de Liste_pred qui est en fait vide:\n",
    "# Liste_pred = Liste_pred[:-1]\n",
    "print(\"\\n\\nlast element deleted\\n\\n\")\n",
    "print('pred : ',len(Liste_pred),'\\ngold : ',len(gold_testset1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaque entité nommée a un : un id et un label dédié au fil des annotations. Ici on cherche à créer un dictionnaire de type {id_EN : label_EN}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "types_labels = {0:0} #On garde cette première valeur pour les tokensqui ne sont pas des EN\n",
    "for pred in Liste_pred:\n",
    "    for ent in pred.ents: \n",
    "        types_labels[ent.label] = ent.label_\n",
    "types_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On créé plusieurs listes avec les tokens des EN <u>prédites</u> : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tokens = []\n",
    "pred_entities = []\n",
    "pred_positions = []\n",
    "\n",
    "for i in range (len(Liste_pred)):\n",
    "    for token in Liste_pred[i]:\n",
    "        pred_tokens.append(token)\n",
    "        pred_entities.append(types_labels[token.ent_type]) \n",
    "        pred_positions.append((i,token, token.idx,token.idx + len(token),types_labels[token.ent_type])) #Position de chacun des token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on obtient une liste `pred_position` composée de tupples contenant:\n",
    "\n",
    "    1) le numéro de l'article \n",
    "    2) le token\n",
    "    3) la pos1 du token\n",
    "    4) la pos2 du token\n",
    "    5) le label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,5247):\n",
    "    list_token_article=[]\n",
    "    token = pred_positions[i]\n",
    "    nexttoken=pred_positions[i-1]\n",
    "    while token[0]==nexttoken[0]:\n",
    "        if token[4] != 0:\n",
    "            newtuple=(token[2],token[3],token[4])\n",
    "            list_token_article.append(newtuple)\n",
    "print(list_token_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on obtient une liste `pred_entities` composée de l'ensemble des labels d'entité nommée associé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'enjeu est alors de comparer ces entités à notre `gold_testset1`. \n",
    "\n",
    "Ici, on découpe le `gold_testset1` en fonction des tokens de pred `pred_position` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_tokens = []  \n",
    "\n",
    "i = 0\n",
    "pos = pred_positions[i]\n",
    "\n",
    "for pos in pred_positions:\n",
    "    i = pos[0] #le numéro de l'article\n",
    "    gold_art = gold_testset1[i] #le dictionnaire de l'article\n",
    "    gold_tokens.append(gold_art[\"text\"][pos[2]:pos[3]])#découpage de gold enfonction de pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pred_positions:\n",
    "    i = pos[0] #le numéro de l'article\n",
    "    gold_art = gold_testset1[i] #le dictionnaire de l'article\n",
    "    gold_tokens.append(gold_art[\"text\"][pos[2]:pos[3]])#découpage de gold enfonction de pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, on créé un dictionnaire qui aura pour clé les labels d'EN et qui au final accueillera les token et positions associés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_set = ['SHS', 'GPE', 'PATH', 'ZOO-ENTO', 'LOC', 'CHEM-LABO', 'ORG']\n",
    "\n",
    "list_ents={}\n",
    "for i in entity_set:\n",
    "    list_ents[i] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice the gold standard text using the token positions from the prediction\n",
    "gold_tokens = []  \n",
    "\n",
    "i = 0\n",
    "pos = pred_positions[i]\n",
    "\n",
    "for pos in pred_positions:\n",
    "    i = pos[0]\n",
    "    if pos[0] == i:\n",
    "        gold_art = gold_testset1[i]\n",
    "        gold_tokens.append(gold_art[\"text\"][pos[2]:pos[3]])\n",
    "# gold_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour rappel, on cherche à avoir un modèle du type : \n",
    "\n",
    "`sents_true_labels = [[{'start_idx': pos0, 'end_idx': pos1, 'text': 'Token', 'type': 'token_label'}, .....]]`\n",
    "   \n",
    "   \n",
    "   ==> Donc dans mon cas je dois avoir pour CHAQUE ARTICLE,une liste contenant les dictionnaires associés \n",
    "   \n",
    "`sents_pred_labels = [[{'start_idx': pos0, 'end_idx': pos1, 'text': 'Token', 'type': 'token_label'}, .....]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_art_ents = {}\n",
    "entpos = []\n",
    "gold_entity_ranges = {}\n",
    "for i in range (len(gold_testset1)): #pour chaque article\n",
    "    for entity in gold_testset1[i]['entities']: #pour chaque token annotés dans gold\n",
    "        liste_pos = list(range(entity[0], entity[1]))\n",
    "        list_art_ents[str(i)]=liste_pos\n",
    "        for ent in entity_set:#Pour chaque label\n",
    "            if entity[2] == ent:\n",
    "                entpos += (list(range(entity[0], entity[1])))\n",
    "            gold_entity_ranges[ent] = entpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_entity_ranges.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_entities = []\n",
    "\n",
    "for pos in pred_positions: #Pour l'ensemble des POS\n",
    "    is_entity = False #set pardéfaut\n",
    "    for label in entity_set: #pour chaque label\n",
    "#         print(label)\n",
    "        if set(range(pos[2], pos[3])) & set(gold_entity_ranges[label]): #Si on trouve le set de lettres dans le dico du label en question \n",
    "            is_entity = True #le pos est bien un NER\n",
    "            gold_entities.append(label) #on ajoute ce label à la liste \n",
    "            break\n",
    "    if not is_entity:\n",
    "        gold_entities.append(0) #on met un 0 si le pos n'est pas un NER de Gold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for label in entity_set:\n",
    "    label_gold = [1 if ent==label else 0 for ent in gold_entities]\n",
    "    label_pred = [1 if ent==label else 0 for ent in pred_entities]\n",
    "\n",
    "    results[label] = (label_gold, label_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels=pd.DataFrame(results,index=[\"gold\",\"pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autres essais : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_gold_ents={'start_idx': None, 'end_idx': None, 'text': None, 'label': None}\n",
    "\n",
    "def gold_to_list():\n",
    "    listetoto=[]\n",
    "    df2=pd.DataFrame()\n",
    "    for i in range(len(gold_testset1)):\n",
    "        Liste_total=[]\n",
    "        Liste_dicos_par_article=[]\n",
    "        for ent in gold_testset1[i]['entities']:\n",
    "            dico_gold_ents[\"start_idx\"] = ent[0]\n",
    "            dico_gold_ents[\"end_idx\"] = ent[1]\n",
    "            dico_gold_ents[\"label\"] = ent[2]\n",
    "            dico_gold_ents[\"text\"] = gold_testset1[i]['text'][ent[0]:ent[1]]\n",
    "            Liste_dicos_par_article.append(dico_gold_ents)\n",
    "        Liste_total.append(Liste_dicos_par_article)\n",
    "        df=pd.DataFrame(Liste_dicos_par_article)\n",
    "        df2=pd.concat([df2,df])\n",
    "        return(df2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
