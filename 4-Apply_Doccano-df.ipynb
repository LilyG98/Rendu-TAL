{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Lily Grumbach\n",
    "    <br>M1 Humanités numériques - Université PSL</h4>\n",
    "<h1><center>Rendu TAIS-TAL </center></h1>\n",
    "<h2><center>Partie TAL</center></h2>\n",
    "<h3><center>3/3 : Application du NLP au df</center></h3>\n",
    "\n",
    "<b><u>PLAN:</u></b>\n",
    "1) Exploration des données\n",
    "<br>\n",
    "2) NER avec Doccano\n",
    "\n",
    "    a) initialisation des données\n",
    "    b) Exploration de la NER préalable de Spacy\n",
    "    c) Mise en place de la stratégie pour l'annotation sur Doccano\n",
    "    d) Entraînement par 5-fold cross validation\n",
    "\n",
    "**3) Application du NLP au df**\n",
    "\n",
    "**Enjeux de la partie 2:**\n",
    "\n",
    "<br></br>\n",
    "**L'objectif à long terme** de cet entraînement NER est de :\n",
    "- Mettre en place une NER qui pourrait être appliquée au full text de chacune des revues une fois les OCR nettoyées. \n",
    "- Appliquer cette NER à la revue des Archives de médecine navale et coloniale (1892-1898)\n",
    "- Alimenter une future base de données relationnelle\n",
    "\n",
    "\n",
    "**Limites de mon travail:** Il me sera nécessaire de mesurer si elle fonctionne bien à la fois sur le reste de la période étudiée ainsi que sur le Bulletin de la Société de Pathologie exotique\n",
    "\n",
    "\n",
    "\n",
    "Sources:\n",
    "* https://stackoverflow.com/questions/44395656/applying-spacy-parser-to-pandas-dataframe-w-multiprocessing \n",
    "\n",
    "\n",
    "* https://towardsdatascience.com/from-dataframe-to-named-entities-4cfaa7251fc0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Généraux : \n",
    "import spacy\n",
    "import fr_core_news_md\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "\n",
    "\n",
    "#Importation de mon module \n",
    "import Training_Doccano\n",
    "from Training_Doccano import pandas_to_doccano\n",
    "\n",
    "#Autres\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'articles dans chaque revue de 1898 à 1908: \n",
      "AHMC : 559 \n",
      "AMN :  638 \n",
      "Total à traiter :  1197\n"
     ]
    }
   ],
   "source": [
    "#Import des dataframes \n",
    "dfAHMC = pd.read_csv(\"./Notebook_data/input/AHMC_articles-originaux_Termine2.tsv\" ,sep='\\t')\n",
    "\n",
    "df_spacyAHMC = dfAHMC.loc[dfAHMC[\"revue_annee\"]<= 1908]\n",
    "df_spacyAHMC = df_spacyAHMC[[\"article_titre\",\"revue_annee\"]]\n",
    "\n",
    "dfAMN=pd.read_csv(\"./Notebook_data/input/AMN-articles-98-08_clean-main.tsv\",sep=\"\\t\")\n",
    "dfAMN=dfAMN[:-2] #les deux derniers rows étaient des nan\n",
    "df_spacyAMN = dfAMN[[\"article_titre\",\"revue_annee\"]]\n",
    "\n",
    "\n",
    "print(\"Nombre d'articles dans chaque revue de 1898 à 1908:\",\n",
    "      \"\\nAHMC :\",len(df_spacyAHMC),\n",
    "      \"\\nAMN : \",len(df_spacyAMN),\n",
    "      \"\\nTotal à traiter : \",len(df_spacyAHMC)+len(df_spacyAMN))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2. Import du NLP entraîné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLP entraîné : \n",
    "nlp_dir = \"./Notebook_data/Training_Doccano/trained_nlp/nlp1\"\n",
    "\n",
    "nlp_test1 = spacy.load(nlp_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction pour appliquer le NLP aux titres du df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rappel des ent.label : \n",
    "\n",
    "*  384: 'GPE'\n",
    "*  4192465394259306970: 'PATH'\n",
    "*  5496441482075855828: 'SHS'\n",
    "*  385: 'LOC'\n",
    "*  11253504087253340061: 'CHEM-LABO'\n",
    "*  383: 'ORG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLPonDF (df):\n",
    "    \n",
    "    #Pour pouvoir analyser les entités dans leur ensemble\n",
    "    listeEnsGPE = []\n",
    "    listeEnsLOC = []\n",
    "    listeEnsORG = []\n",
    "    listeEnsPATH = []\n",
    "    listeEnsSHS=[]\n",
    "    listeEnsCHEMLABO = []\n",
    "    \n",
    "    df = pd.concat(\n",
    "    [\n",
    "        df,\n",
    "        pd.DataFrame(\n",
    "            [[\"\", \"\", \"\",\"\", \"\", \"\"]], \n",
    "            index=df.index, \n",
    "            columns=['GPE_ents', 'LOC_ents', 'ORG_ents',\"PATH_ents\",\"SHS_ents\",\"CHEM-LABO_ents\"]\n",
    "        )\n",
    "    ], axis=1\n",
    ")\n",
    "    \n",
    "    \n",
    "    for i in range (len(df)):\n",
    "        listeGPE = []\n",
    "        listeLOC = []\n",
    "        listeORG = []\n",
    "        listePATH = []\n",
    "        listeSHS=[]\n",
    "        listeCHEMLABO = []\n",
    "\n",
    "        titre = df.iloc[i,0]\n",
    "        tokenTitre = nlp_test1(titre)\n",
    "\n",
    "        for ent in tokenTitre.ents:\n",
    "            #GPE\n",
    "            if ent.label_ == \"GPE\" :\n",
    "                listeGPE.append(ent.text)\n",
    "                listeEnsGPE.append(ent.text)\n",
    "            GPE=','.join([str(gpe)for gpe in listeGPE])\n",
    "            df.iloc[i,2] =GPE\n",
    "\n",
    "            #LOC : \n",
    "            if ent.label == 385:\n",
    "                listeLOC.append(ent.text)\n",
    "                listeEnsLOC.append(ent.text)\n",
    "            LOC=','.join([str(loc)for loc in listeLOC])\n",
    "            df.iloc[i,3] = LOC\n",
    "\n",
    "            #ORG : \n",
    "            if ent.label == 383:\n",
    "                listeORG.append(ent.text)\n",
    "                listeEnsORG.append(ent.text)\n",
    "            ORG=','.join([str(org)for org in listeORG])\n",
    "            df.iloc[i,4] = ORG\n",
    "    \n",
    "            #PATH : \n",
    "            if ent.label == 4192465394259306970:\n",
    "                listePATH.append(ent.text)\n",
    "            PATH = ','.join([str(path)for path in listePATH])\n",
    "            df.iloc[i,5] = PATH\n",
    "        \n",
    "            #SHS : \n",
    "            if ent.label == 5496441482075855828:\n",
    "                listeSHS.append(ent.text)\n",
    "                listeEnsORG.append(ent.text)\n",
    "            SHS = ','.join([str(shs)for shs in listeSHS])\n",
    "            df.iloc[i,6] =SHS\n",
    "    \n",
    "            #CHEM-LABO : \n",
    "            if ent.label == 11253504087253340061:\n",
    "                listeCHEMLABO.append(ent.text)\n",
    "                listeEnsCHEMLABO.append(ent.text)\n",
    "            CHEMLABO = ','.join([str(chemlabo)for chemlabo in listeCHEMLABO])\n",
    "            df.iloc[i,7] =CHEMLABO\n",
    "    \n",
    "    return df,listeEnsGPE,listeEnsLOC,listeEnsORG,listeEnsPATH,listeEnsSHS,listeEnsCHEMLABO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application du NLP aux AHMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spacyAHMCannotations,listeEnsGPE,AHMC_listeEnsLOC,AHMC_listeEnsORG,AHMC_listeEnsPATH,AHMC_listeEnsSHS,AHMC_listeEnsCHEMLABO=NLPonDF(df_spacyAHMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spacyAHMCannotations.to_csv(\"./Notebook_data/Apply_Doccano-df/dfAHMCannotations.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(AHMC_listeEnsLOC).to_csv(\"./Notebook_data/Apply_Doccano-df/AHMC_listeEnsLoc.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application NLP aux AMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spacyAMNannotations = NLPonDF(df_spacyAMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spacyAMNannotations.to_csv(\"./Notebook_data/Apply_Doccano-df/dfAMNannotations.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration sur l'ensemble des colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AHMC\n",
    "tokensAHMC = nlp_test1(''.join(str(df_spacyAHMC.article_titre.tolist())))\n",
    "\n",
    "#AMN\n",
    "tokensAMN = nlp_test1(''.join(str(df_spacyAMN.article_titre.tolist())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Extraction des entités"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemsAHMC = [x.text for x in tokensAHMC.ents]\n",
    "itemsAMN = [x.text for x in tokensAMN.ents]\n",
    "\n",
    "#Voir les 20 principaux:\n",
    "# Counter(itemsAHMC).most_common(20)\n",
    "# Counter(itemsAMN).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
